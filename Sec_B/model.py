# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tVV7CtLNUlr2xgwoMBZ1hrRpsDIZvVlc

# Loading Dataset
"""

from google.colab import files
files.upload()

from google.colab import files
files.upload()

"""# Importing all the necesssary libraries"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.model_selection import KFold
import numpy as np
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import average_precision_score,classification_report,confusion_matrix,precision_recall_curve
from sklearn.model_selection import train_test_split
import tensorflow as tf

# Reading data through pandas library
data = pd.read_csv("zoo.data")

data.head()

data.info()

"""# Data Preprocessing"""

# Renaming columns of data using the "zoo.names" file
data.columns =['animal_name','hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize','class_type']
data.head()

df = pd.DataFrame({"animal_name":['aardvark'],"hair":[1],"feathers":[0],"eggs":[0],"milk":[1],"airborne":[0],"aquatic":[0],"predator":[1],'toothed':[1],'backbone':[1],'breathes':[1],'venomous':[0],'fins':[0],"legs":[4],'tail':[0],'domestic':[0],'catsize':[1],'class_type':[1]})

train_data=df.append(data,ignore_index=True)
train_data.head()

train_data.shape

columnsTitles=['animal_name','hair','feathers','eggs','milk','airborne','aquatic','predator','toothed','backbone','breathes','venomous','fins','legs','tail','domestic','catsize','class_type']
train_data=train_data.reindex(columns=columnsTitles)
train_data.head()

# plot to see class distribution
sns.countplot(train_data['class_type'],label="Count")

# extracting features column from the dataset
x_data = train_data.iloc[:,:-1]
x_data.head()
x_data.shape

# extracting target class from dataset
y_data= train_data.iloc[:,-1:]
y_data.head()
y_data.shape

# dropping the column "animal_name" since this feature is not informative
x_name = x_data['animal_name']

x_data = x_data.iloc[:,1:]

x_data.head()

X = np.array(x_data)
y= np.array(y_data)

# Since it is a multiclass dataset , we need to use label_binarizer to transform the feature vector according to no. of classes
Y = label_binarize(y, classes=[0, 1, 2,3,4,5,6])
n_classes = Y.shape[1]
n_classes

"""# Model Fitting

## 1. SVM Model for this multiclass classification
"""

# SVC with linear kernel 
scores = []
clf = OneVsRestClassifier(SVC(kernel='linear'))   # OneVsRest Classifier for multiclass classification

# Using KFold  for cross validation with n_folds = 5
cv = KFold(n_splits=5, random_state=None, shuffle=False)    
for train_index, test_index in cv.split(X):
    
    X_train, X_test, y_train, y_test = X[train_index], X[test_index], Y[train_index], Y[test_index]
    clf.fit(X_train, y_train)
    scores.append(clf.score(X_test, y_test))
    y_score = clf.decision_function(X_test)
    
# Classification Acuuracy
print("Classification Accuracy:",np.mean(scores))
    
# Precision Score
precision = dict()
recall = dict()
average_precision = dict()
for i in range(n_classes):
    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],
                                                        y_score[:, i])
    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])

# A "micro-average": quantifying score on all classes jointly
precision["micro"], recall["micro"], _ = precision_recall_curve(y_test.ravel(),
    y_score.ravel())
average_precision["micro"] = average_precision_score(y_test, y_score,
                                                     average="micro")
print('Average precision score, micro-averaged over all classes: {0:0.2f}'
      .format(average_precision["micro"]))

# plotiing to ROC curve for model performance for linear kernel of SVM
plt.figure()
plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,
         where='post')


plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title(
    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'
    .format(average_precision["micro"]))

# SVC with rbf kernel 
scores = []
clf = OneVsRestClassifier(SVC(kernel='rbf'))
cv = KFold(n_splits=5, random_state=None, shuffle=False)
for train_index, test_index in cv.split(X):
    
    X_train, X_test, y_train, y_test = X[train_index], X[test_index], Y[train_index], Y[test_index]
    clf.fit(X_train, y_train)
    scores.append(clf.score(X_test, y_test))
    y_score = clf.decision_function(X_test)
    
# Classification Acuuracy
print("Classification Accuracy:",np.mean(scores))
    
# Precision Score
precision = dict()
recall = dict()
average_precision = dict()
for i in range(n_classes):
    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],
                                                        y_score[:, i])
    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])

# A "micro-average": quantifying score on all classes jointly
precision["micro"], recall["micro"], _ = precision_recall_curve(y_test.ravel(),
    y_score.ravel())
average_precision["micro"] = average_precision_score(y_test, y_score,
                                                     average="micro")
print('Average precision score, micro-averaged over all classes: {0:0.2f}'
      .format(average_precision["micro"]))

# plotiing to ROC curve for model performance for rbf kernel of SVM
plt.figure()
plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,
         where='post')


plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title(
    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'
    .format(average_precision["micro"]))

# SVC with polynomial kernel 
scores = []
clf = OneVsRestClassifier(SVC(kernel='poly'))
cv = KFold(n_splits=5, random_state=None, shuffle=False)
for train_index, test_index in cv.split(X):
    
    X_train, X_test, y_train, y_test = X[train_index], X[test_index], Y[train_index], Y[test_index]
    clf.fit(X_train, y_train)
    scores.append(clf.score(X_test, y_test))
    y_score = clf.decision_function(X_test)
    
# Classification Acuuracy
print("Classification Accuracy:",np.mean(scores))
    
# Precision Score
precision = dict()
recall = dict()
average_precision = dict()
for i in range(n_classes):
    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],
                                                        y_score[:, i])
    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])

# A "micro-average": quantifying score on all classes jointly
precision["micro"], recall["micro"], _ = precision_recall_curve(y_test.ravel(),
    y_score.ravel())
average_precision["micro"] = average_precision_score(y_test, y_score,
                                                     average="micro")
print('Average precision score, micro-averaged over all classes: {0:0.2f}'
      .format(average_precision["micro"]))

# plotiing to ROC curve for model performance for polynomial kernel of SVM
plt.figure()
plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,
         where='post')


plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title(
    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'
    .format(average_precision["micro"]))

# SVC with sigmoid kernel 
scores = []
clf = OneVsRestClassifier(SVC(kernel='sigmoid'))
cv = KFold(n_splits=5, random_state=None, shuffle=False)
for train_index, test_index in cv.split(X):
    
    X_train, X_test, y_train, y_test = X[train_index], X[test_index], Y[train_index], Y[test_index]
    clf.fit(X_train, y_train)
    scores.append(clf.score(X_test, y_test))
    y_score = clf.decision_function(X_test)
    
# Classification Acuuracy
print("Classification Accuracy:",np.mean(scores))
    
# Precision Score
precision = dict()
recall = dict()
average_precision = dict()
for i in range(n_classes):
    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],
                                                        y_score[:, i])
    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])

# A "micro-average": quantifying score on all classes jointly
precision["micro"], recall["micro"], _ = precision_recall_curve(y_test.ravel(),
    y_score.ravel())
average_precision["micro"] = average_precision_score(y_test, y_score,
                                                     average="micro")
print('Average precision score, micro-averaged over all classes: {0:0.2f}'
      .format(average_precision["micro"]))

# plotiing to ROC curve for model performance for sigmoid kernel of SVM
plt.figure()
plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,
         where='post')


plt.xlabel('Recall')
plt.ylabel('Precision')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.title(
    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'
    .format(average_precision["micro"]))

"""##2.  Back Propagation Neural Network using Tensorflow Framework"""

# Train-test split cross validation
train_x, test_x, train_y, test_y = train_test_split(x_data, y_data, test_size=0.3, random_state=42, stratify=y_data)
print("Training Data has",train_x.shape)
print("Testing Data has",test_x.shape)

train_y.shape

X = tf.placeholder(tf.float32, [None,16]) 
Y = tf.placeholder(tf.int32, [None, 1])

Y_one_hot = tf.one_hot(Y, 7)  # one hot encoding
Y_one_hot = tf.reshape(Y_one_hot, [-1, 7])

W = tf.Variable(tf.random_normal([16, 7],seed=0), name='weight')
b = tf.Variable(tf.random_normal([7],seed=0), name='bias')

logits = tf.matmul(X, W) + b

hypothesis = tf.nn.softmax(logits)

cost_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y_one_hot)
cost = tf.reduce_mean(cost_i)

# Training the model using Gradient Descent Algorithm 
train  = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)

# Alternate algorithm for training - Adam Optimizer
#train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)

prediction = tf.argmax(hypothesis, 1)
correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

"""### Running the tensorflow session and getting evaluation metrics"""

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    for step in range(5001):
        sess.run(train, feed_dict={X: train_x, Y: train_y})
        if step % 1000 == 0:
            loss, acc = sess.run([cost, accuracy], feed_dict={X: train_x, Y: train_y})
            print("Step: {:5}\tLoss: {:.3f}\tAcc: {:.2%}".format(step, loss, acc))
            
    train_acc = sess.run(accuracy, feed_dict={X: train_x, Y: train_y})
    test_acc,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={X: test_x, Y: test_y})
    print("Model Prediction =", train_acc)
    print("Test Prediction =", test_acc)

